language: python
python: 2.7
sudo: false
addons:
  apt:
    packages:
    - python-qt4
env:
- WHEELHOUSE=$HOME/.cache/wheelhouse PIP_FIND_LINKS=file://$WHEELHOUSE PIP_WHEEL_DIR=$WHEELHOUSE
cache:
  directories:
  - "$HOME/.cache/pip"
  - "$HOME/.cache/wheelhouse"
  - slyd/node_modules
  - slyd/bower_components
install:
- pip wheel -r ./slybot/requirements.txt
- pip install --use-wheel -r ./slybot/requirements.txt
- pip install -e ./slybot[tests]
- pip wheel -r ./slyd/requirements.txt
- pip install --use-wheel -r ./slyd/requirements.txt
- cd ./slyd
- npm install -g bower
- npm install
- bower install
- cd ../
script:
- cd ./slybot
- nosetests --with-doctest
- cd ../slyd
- npm test
- PYTHONPATH=$PYTHONPATH:/usr/lib/python2.7/dist-packages/ nosetests --with-doctest
- cd ../
before_deploy: cd ./slybot
deploy:
  provider: pypi
  distributions: sdist bdist_wheel
  user: scrapinghub
  password:
    secure: S5hZT2YBncUSkPTyR5RUQnACfTsW2ZtpHeQucIamKWN+xkE8KK9O0cWUMuKQ0q3U5ShFkZdhO4PnBjvtP54Dq9IogJAudkDJCylctf4qGoIlWu01mAoJzcUfrS5KW+VolF/opBJObwG38EIOOsVy9UYq7DeQcryAAG1RuMjONAk=
  on:
    all_branches: true
    tags: true
    repo: scrapinghub/portia
    condition: "$TRAVIS_TAG =~ ^slybot-[0-9][.][0-9]*"
